# Paper Note - [Large Language Models Are Human-Level Prompt Engineers](https://arxiv.org/abs/2211.01910)

## Overview
This work is about automatic prompt engineering. 

It generate some candidate prompts first and then using a iterative algorithms 
to select better ones among them, until the best one left. 

The selection is based on a **score function**, with each candidate prompt, 
we use scorne function to evaluate the inference results generated by that 
prompt based on a pre-built training dataset. 

In paper the author use accuracy and log-probability as score function, but 
it's easy to replace them with self-defined ones.

As LLMs inference are very slow and expensive, so it's not realistic to run 
inference for each candidate prompt on full training dataset. The solution is 
first sampling full training dataset into several non-overlapping small subsets.
Then we iteratively run the evaluation for all (left) candidates with **score 
function**. In each iteration we only use one sampled subset, and only keep 
candidate prompts which scores are ranked in ${\rm topk\%}$.

With above algorithm. We can iteratively drop low quality prompt without spend 
a large amount of resources in each iteration. The iteration will be stopped 
when one one prompt left, which is the best one.


## Algorithms
* Step 0: Define data and some parameters
    * **Training data**: $D_{train}\{(Q, A)\}$, $Q$ and $A$ are input and output (text) for each example.
    * **Score function**: $f: \rho \times (Q, A) \rightarrow \mathbb{R}$.
    * **Top-K percentage to select**: ${\rm topk\%}$.
* Step 1: Generate initial **candidate prompts** set $U \leftarrow \{\rho_{i}, ..., \rho_{m}\}$, this can be:
    * a. Make human design some prompts
    * b. Auto generation with LLMs
        * **Forward Mode Generation**: Use **instrction induction** technique, like [From Few Examples to Natural Language Task Descriptions](https://aclanthology.org/2023.acl-long.108.pdf)
            * **Cons**:
                * The generated instruction will be typically used as the prefix/begining of the input text, but during the generation it's generated at last naturally. **So based on the probability understanding of LLMs, it has larger probability to be generated as the description of input-to-output task, we can not guarantee it also has high probability to prompt LLMs with input to generate output**. 
                * Need extra efforts to suit into different tasks.
        * **Reverse Mode Generation**: Can solve cons of forward mode generation, as it's leverate LLMs **infilling** capacity, which can fill or insert instruction (description of task) at anyplace of the text.
            * Refer to [Efficient training of language models to fill in the middle](https://arxiv.org/abs/2207.14255)
* Step 2: Training subsets building, sampling full training datasets into non-overlapping subsets.
* Step 3: Iterative candidate prompts selection
    * Randomly choose a training subset $D_{train}^i$ which was not used before.
    * For all candidates in current $U$, calculate score with score function.
    * Update $U$ by only keep candidates which scorex are ranking in $topk\%$, remove left candidates out from $U$.
    * If only one candidate left, then end iteration. If not and repeat.


## Thoughts
### Pros
* The ideas is quite clear and explanable.
* The learning process is computational efficency.
### Cons
* This algorithm optimize the prompt as a whole, which means when we have a "structured" prompt, for example with CoT (which contains multiple steps) or prompt with multiple instructions, we cannot optimize the prompt at a finer granularityï¼Œ for example, optimize one specific instruction or step in prompt.
* Needs labeled training data
